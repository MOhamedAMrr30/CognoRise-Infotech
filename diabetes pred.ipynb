{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaU8r3ALWBhP",
        "outputId": "85a83e26-fd79-4d0c-e0a8-a426914ba592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98     18292\n",
            "           1       0.86      0.61      0.72      1708\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.91      0.80      0.85     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n",
            "Random Forest Classifier Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98     18292\n",
            "           1       0.95      0.69      0.80      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.96      0.84      0.89     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n",
            "AdaBoost Classifier Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98     18292\n",
            "           1       0.97      0.70      0.81      1708\n",
            "\n",
            "    accuracy                           0.97     20000\n",
            "   macro avg       0.97      0.85      0.90     20000\n",
            "weighted avg       0.97      0.97      0.97     20000\n",
            "\n",
            "KNN Classifier Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     18292\n",
            "           1       0.87      0.52      0.65      1708\n",
            "\n",
            "    accuracy                           0.95     20000\n",
            "   macro avg       0.91      0.76      0.81     20000\n",
            "weighted avg       0.95      0.95      0.95     20000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes_file_path = '/content/diabetes_prediction_dataset.csv'\n",
        "diabetes_df = pd.read_csv(diabetes_file_path)\n",
        "\n",
        "# Encoding categorical variables (gender and smoking_history)\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "diabetes_df['gender'] = label_encoder.fit_transform(diabetes_df['gender'])\n",
        "diabetes_df['smoking_history'] = label_encoder.fit_transform(diabetes_df['smoking_history'])\n",
        "\n",
        "# Splitting the data into features (X) and labels (y)\n",
        "X = diabetes_df.drop('diabetes', axis=1)\n",
        "y = diabetes_df['diabetes']\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "print(\"Logistic Regression Report:\\n\", classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# 2. Random Forest Classifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Classifier Report:\\n\", classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# 3. AdaBoost Classifier\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred_ada = ada.predict(X_test)\n",
        "print(\"AdaBoost Classifier Report:\\n\", classification_report(y_test, y_pred_ada))\n",
        "\n",
        "# 4. K-Nearest Neighbors (KNN) Classifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "print(\"KNN Classifier Report:\\n\", classification_report(y_test, y_pred_knn))\n"
      ]
    }
  ]
}